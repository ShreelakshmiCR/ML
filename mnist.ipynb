{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqJyJHINDmEV2oXgDKeBS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreelakshmiCR/ML/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBFsEvkA-Kl-"
      },
      "outputs": [],
      "source": [
        "## imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "cnn_log_dir = 'logs/cnn/' + current_time + '/train'\n",
        "fc_log_dir = 'logs/fc/' + current_time + '/train'\n",
        "\n",
        "cnn_writer = SummaryWriter(cnn_log_dir)\n",
        "fc_writer = SummaryWriter(fc_log_dir)"
      ],
      "metadata": {
        "id": "lNVkC-qW-U0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-Parameters\n",
        "args={}\n",
        "args['batch_size'] = 64\n",
        "args['epochs'] = 3  #The number of Epochs is the number of times you go through the full dataset.\n",
        "args['lr'] = 0.01 #Learning rate is how fast it will decend.\n",
        "args['seed'] = 1 #random seed\n",
        "args['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "IawYUpNk-YEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aY84YXOS-biE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading data, splits\n",
        "torch.manual_seed(args['seed'])\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])\n",
        "\n",
        "mnist_dataset_train = datasets.MNIST('dataset/', train=True, download=True,\n",
        "                   transform=mnist_transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_dataset_train,\n",
        "    batch_size=args['batch_size'], shuffle=True)\n",
        "\n",
        "mnist_dataset_test = datasets.MNIST('dataset/', train=False, download=True,\n",
        "                   transform=mnist_transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(mnist_dataset_test,\n",
        "    batch_size=args['batch_size'], shuffle=True)"
      ],
      "metadata": {
        "id": "pu7uBzEXp1jn",
        "outputId": "f4d52d99-9473-4d77-f0b5-3f05241d3a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 104144703.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 22255317.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25566026.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15849025.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(mnist_dataset_train))\n",
        "print(len(mnist_dataset_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCDzssaM-hNj",
        "outputId": "a91761a1-747d-401b-a27c-93fa51fc7d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model architecture\n",
        "# Fully-connected\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, image_shape, num_classes):\n",
        "        super(FullyConnected, self).__init__()\n",
        "        self.input_size = np.prod(image_shape)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.fc1 = nn.Linear(self.input_size, self.input_size//2)\n",
        "        self.fc2 = nn.Linear(self.input_size//2, self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# CNNs\n",
        "class CNN(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities.\n",
        "        return x"
      ],
      "metadata": {
        "id": "aZzJ3FZT-l1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_model = FullyConnected((28, 28), 10).to(args[\"device\"])\n",
        "cnn_model = CNN().to(args[\"device\"])\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1hXoBhtw-oac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Adam optimizer\n",
        "# other optimizers : https://pytorch.org/docs/stable/optim.html#:~:text=torch.Tensor%20s.-,Algorithms,-Adadelta\n",
        "fc_optimizer = optim.Adam(fc_model.parameters(), lr=args[\"lr\"])\n",
        "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=args[\"lr\"])"
      ],
      "metadata": {
        "id": "G7cc2zoi-rpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Printing nummber of parameters\n",
        "print(f\"Number of parameters in fully connected model : {sum(p.numel() for p in fc_model.parameters() if p.requires_grad)}\")\n",
        "print(f\"Number of parameters in CNN model : {sum(p.numel() for p in cnn_model.parameters() if p.requires_grad)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On0s1qHH-uWp",
        "outputId": "d328e29f-1e0a-475f-d925-9b17b0549d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters in fully connected model : 311650\n",
            "Number of parameters in CNN model : 21840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Accuracy\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=args[\"device\"])\n",
        "            y = y.to(device=args[\"device\"])\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples"
      ],
      "metadata": {
        "id": "Ji-wQWrY-yNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train loop\n",
        "fc_model.train()\n",
        "cnn_model.train()\n",
        "\n",
        "global_step = 0\n",
        "for ep in range(args[\"epochs\"]):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data = data.to(args[\"device\"])\n",
        "      target = target.to(args[\"device\"])\n",
        "\n",
        "      #This will zero out the gradients for this batch.\n",
        "      fc_optimizer.zero_grad()\n",
        "      cnn_optimizer.zero_grad()\n",
        "      # Fetch model output\n",
        "      fc_output = fc_model(data)\n",
        "      cnn_output =  cnn_model(data)\n",
        "\n",
        "      #Fetch loss\n",
        "      fc_loss = loss_fn(fc_output, target)\n",
        "      cnn_loss = loss_fn(cnn_output, target)\n",
        "\n",
        "      # Saving loss values for plotting\n",
        "      cnn_writer.add_scalar('loss', cnn_loss.item(), global_step)\n",
        "      fc_writer.add_scalar('loss', fc_loss.item(), global_step)\n",
        "      global_step += 1\n",
        "\n",
        "      #dloss/dx for every Variable\n",
        "      fc_loss.backward()\n",
        "      cnn_loss.backward()\n",
        "\n",
        "      #to do a one-step update on our parameter.\n",
        "      fc_optimizer.step()\n",
        "      cnn_optimizer.step()"
      ],
      "metadata": {
        "id": "4OGQbNDd-1uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#\"*10 + f\"  Epoch : {ep}  \"  + \"#\"*10)\n",
        "  print(\"Fully-connected\")\n",
        "  print(f\"Accuracy on training set: {check_accuracy(train_loader, fc_model)*100:.2f}\")\n",
        "  print(f\"Accuracy on test set: {check_accuracy(test_loader, fc_model)*100:.2f}\")\n",
        "  print()\n",
        "  print(\"CNN\")\n",
        "  print(f\"Accuracy on training set: {check_accuracy(train_loader, cnn_model)*100:.2f}\")\n",
        "  print(f\"Accuracy on test set: {check_accuracy(test_loader, cnn_model)*100:.2f}\")\n",
        "  print(\"#\"*30)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MVMsGl99-4zK",
        "outputId": "1f21f957-93aa-4fdc-e936-749cc7628513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-cfb76c1956ad>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(\"Fully-connected\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}